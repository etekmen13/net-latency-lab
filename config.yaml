global:
  remote_project_root: "/root/net-latency-lab"
  local_project_root: "."
  user: "root"
  local_data_dir: "analysis/data"
  nodes:
    receiver_ip: "192.168.1.10" 
    sender_ip: "192.168.1.11"
    receiver_iface: "eth0"
benchmarks:
  # Benchmark 1: Throughput Saturation
  # Sweeps from 1k to 100k PPS to find where the baseline breaks
  - name: "baseline"
    enabled: true
    receiver:
      binary: "receiver_baseline"
      cpu_affinity: 3
      processing_time_ns: 10000
    sender:
      mode: "steady"
      duration_sec: 30
      rates_pps: [1000, 2500, 5000, 7500, 10000, 25000, 50000, 75000, 100000]
      payload_size: 64
  - name: "threaded"
    enabled: true
    receiver:
      binary: "receiver_threaded"
      cpu_affinity: 3
      batch_size: [1,16,32]  
      processing_time_ns: 10000
    sender:
      mode: "steady"
      duration_sec: 30
      rates_pps: [1000, 2500, 5000, 7500, 10000, 25000, 50000, 75000, 100000]
      payload_size: 64


  # Benchmark 2: Burst Resilience
  # Tests how the threaded receiver handles micro-bursts compared to steady traffic
  - name: "threaded_burst_test"
    enabled: true
    receiver:
      binary: "receiver_threaded"
      cpu_affinity: 2
      batch_size: 32 # Tuning parameter for the SPSC queue
    sender:
      mode: "burst"
      duration_sec: 15
      rates_pps: [50000] # Average rate
      burst_sizes: [10, 50, 100] # Packets per burst
